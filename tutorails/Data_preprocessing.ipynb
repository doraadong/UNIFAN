{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import argparse\n",
    "import time\n",
    "from os.path import exists\n",
    "import collections\n",
    "from typing import Iterable\n",
    "import pickle                                                                                \n",
    "from collections import Counter\n",
    "\n",
    "import scanpy as sc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess input data \n",
    "\n",
    "Here we show how we preprocessed the datasets we used in our manuscript, except for the Tabula Muris datasets which we already covered in our examples (see [getExample.py](https://github.com/doraadong/UNIFAN/blob/main/tutorails/getExample.py) for details). Other than the pacakges imported above, we also use [mygene](https://pypi.org/project/mygene/) package to convert ENSEMBL IDs to gene symbols for the HuBMAP datasets. \n",
    "\n",
    "**Table of Content**\n",
    "\n",
    "1. [Preprocess pbmc28K](#1)\n",
    "2. [Preprocess pbmc68K](#2)\n",
    "3. [Preprocess Atlas lung](#3)\n",
    "4. [Preprocess HuBMAP datasets](#4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_cutoffs = {'lung': 500, 'lymph_node':200, 'spleen':200, 'thymus':200, 'pbmc68k':200, 'pbmc28k':200}\n",
    "gene_cutoffs = {'lung': 5, 'lymph_node':3, 'spleen':3, 'thymus':3, 'pbmc68k':3, 'pbmc28k':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_raw = False\n",
    "save_processed = True\n",
    "\n",
    "topk = 2000\n",
    "select_genes = False\n",
    "\n",
    "if select_genes: \n",
    "    condition = f\"_top{topk}\"\n",
    "else:\n",
    "    condition = f\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Preprocess pbmc28k\n",
    "<a id=1></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tissue = \"pbmc28k\"\n",
    "data_name = \"pbmc\"\n",
    "\n",
    "parent_folder = f\"../input/{data_name}\"\n",
    "labels = pd.read_csv(f\"{parent_folder}/{tissue}/barcodes_to_cell_types.tsv\", sep=\"\\t\")\n",
    "\n",
    "barcodes = [i.split('_')[0] for i in labels['barcode']]\n",
    "lanes = [i.split('_')[1] for i in labels['barcode']]\n",
    "labels['code'] = barcodes\n",
    "labels['lane'] = lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnData object with n_obs × n_vars = 4309 × 32738\n",
      "    var: 'gene_ids'\n",
      "AnnData object with n_obs × n_vars = 3844 × 32738\n",
      "    var: 'gene_ids'\n",
      "AnnData object with n_obs × n_vars = 4998 × 32738\n",
      "    var: 'gene_ids'\n",
      "AnnData object with n_obs × n_vars = 3392 × 32738\n",
      "    var: 'gene_ids'\n",
      "AnnData object with n_obs × n_vars = 2868 × 32738\n",
      "    var: 'gene_ids'\n",
      "AnnData object with n_obs × n_vars = 3685 × 32738\n",
      "    var: 'gene_ids'\n",
      "AnnData object with n_obs × n_vars = 3198 × 32738\n",
      "    var: 'gene_ids'\n",
      "AnnData object with n_obs × n_vars = 2561 × 32738\n",
      "    var: 'gene_ids'\n"
     ]
    }
   ],
   "source": [
    "full_data = None\n",
    "pre_genes = None \n",
    "\n",
    "for i in range(1, 9):\n",
    "    cur_lane = f\"lane_{i}\"\n",
    "    \n",
    "    parent_folder = f\"../input/{data_name}\"\n",
    "    adata = sc.read_10x_mtx(f\"{parent_folder}/{tissue}/{cur_lane}/\", var_names='gene_symbols', cache=True)          \n",
    "    adata.var_names_make_unique() \n",
    "    \n",
    "    print(adata)\n",
    "    \n",
    "    # get observation idx\n",
    "    _codes = [i.split('-')[0] for i in adata.obs.index.values]\n",
    "    # all barcodes having labels are in the expression file \n",
    "    assert len(set(labels[labels['lane'] == f\"lane{i}\"].code.values) - set(_codes)) == 0\n",
    "\n",
    "    _others = [i.split('-')[1] for i in adata.obs.index.values]\n",
    "    assert (np.array(_others) == '1').all()\n",
    "    \n",
    "    # get labels \n",
    "    cur_labels = labels[labels['lane'] == f\"lane{i}\"].copy().reset_index()\n",
    "    cur_labels = cur_labels[['code', 'cell_type']]\n",
    "\n",
    "    df_codes = pd.DataFrame(_codes)\n",
    "    df_codes.columns = ['code']\n",
    "    df_codes = df_codes.merge(cur_labels, left_on = 'code', right_on = 'code', how = 'left')\n",
    "\n",
    "    # same order as in adata\n",
    "    assert (df_codes['code'].values == np.array(_codes)).all()\n",
    "    \n",
    "    adata.obs['label'] = df_codes['cell_type'].values\n",
    "    \n",
    "    if full_data is not None:\n",
    "        full_data = full_data.concatenate(adata)\n",
    "    else:\n",
    "        full_data = adata\n",
    "    \n",
    "    # check if gene id same for all data\n",
    "    cur_genes = adata.var['gene_ids'].values\n",
    "    if pre_genes is not None:\n",
    "        assert (pre_genes == cur_genes).all()\n",
    "    pre_genes = cur_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# keep only those with labels\n",
    "full_data = full_data[~full_data.obs.label.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "View of AnnData object with n_obs × n_vars = 25185 × 32738\n",
       "    obs: 'label', 'batch'\n",
       "    var: 'gene_ids'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trying to set attribute `.obs` of view, copying.\n",
      "... storing 'label' as categorical\n"
     ]
    }
   ],
   "source": [
    "# filtering \n",
    "sc.pp.filter_cells(full_data, min_genes=cell_cutoffs[tissue])\n",
    "sc.pp.filter_genes(full_data, min_cells=gene_cutoffs[tissue])\n",
    "\n",
    "if save_raw:\n",
    "    filename = f\"{tissue}_raw{condition}.h5ad\"\n",
    "    full_data.write_h5ad(os.path.join(parent_folder, filename))\n",
    "\n",
    "if save_processed:\n",
    "    # selecting genes using Seurat v3 method \n",
    "    sc.pp.highly_variable_genes(full_data, n_top_genes=topk, flavor='seurat_v3')\n",
    "    if select_genes:\n",
    "        full_data = full_data[:, full_data.var.highly_variable]\n",
    "\n",
    "    # normalize \n",
    "    sc.pp.normalize_total(full_data, target_sum=1e4)\n",
    "    sc.pp.log1p(full_data)\n",
    "\n",
    "    # adata.raw = adata\n",
    "    sc.pp.scale(full_data, max_value=10)\n",
    "\n",
    "    # save \n",
    "    try:\n",
    "        full_data.__dict__['_raw'].__dict__['_var'] = full_data.__dict__['_raw'].__dict__['_var'].rename(columns={'_index': 'features'})\n",
    "    except AttributeError:\n",
    "        pass \n",
    "\n",
    "    filename = f\"{tissue}_processed{condition}.h5ad\"\n",
    "    full_data.write_h5ad(os.path.join(parent_folder, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocessing pbmc68k\n",
    "<a id=2></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'label' as categorical\n"
     ]
    }
   ],
   "source": [
    "tissue = \"pbmc68k\"\n",
    "data_name = \"pbmc\"\n",
    "\n",
    "parent_folder = f\"../input/{data_name}\"\n",
    "full_data = sc.read_10x_mtx(f\"{parent_folder}/{tissue}/filtered_matrices_mex/hg19/\", var_names='gene_symbols',cache=True)          \n",
    "full_data.var_names_make_unique() \n",
    "\n",
    "# get labels \n",
    "labels = pd.read_csv(f\"{parent_folder}/{tissue}/zheng17-cell-labels.txt\", sep = \"\\t\")\n",
    "\n",
    "# check if barcodes same\n",
    "barcodes = pd.read_csv(\"../input/pbmc/pbmc68k/filtered_matrices_mex/hg19/barcodes.tsv\", header = None)\n",
    "assert (labels['barcode'].values == barcodes[0].values).all()\n",
    "\n",
    "full_data.obs['label'] = labels['bulk_labels'].values\n",
    "\n",
    "# filtering \n",
    "sc.pp.filter_cells(full_data, min_genes=cell_cutoffs[tissue]) \n",
    "sc.pp.filter_genes(full_data, min_cells=gene_cutoffs[tissue])\n",
    "\n",
    "if save_raw:\n",
    "    filename = f\"{tissue}_raw{condition}.h5ad\"\n",
    "    full_data.write_h5ad(os.path.join(parent_folder, filename))\n",
    "    \n",
    "if save_processed:\n",
    "    # selecting genes using Seurat v3 method \n",
    "    sc.pp.highly_variable_genes(full_data, n_top_genes=topk, flavor='seurat_v3')\n",
    "    if select_genes:\n",
    "        full_data = full_data[:, full_data.var.highly_variable]\n",
    "\n",
    "    # normalie \n",
    "    sc.pp.normalize_total(full_data, target_sum=1e4)\n",
    "    sc.pp.log1p(full_data)\n",
    "\n",
    "    # adata.raw = adata\n",
    "    sc.pp.scale(full_data, max_value=10)\n",
    "\n",
    "    # save \n",
    "    try:\n",
    "        full_data.__dict__['_raw'].__dict__['_var'] = full_data.__dict__['_raw'].__dict__['_var'].rename(columns={'_index': 'features'})\n",
    "    except AttributeError:\n",
    "        pass \n",
    "\n",
    "    filename = f\"{tissue}_processed{condition}.h5ad\"\n",
    "    full_data.write_h5ad(os.path.join(parent_folder, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preprocess Atlas lung\n",
    "<a id=3></a>\n",
    "\n",
    "Before running the following code, make sure you have done the following: \n",
    "\n",
    "1. Download the following two files from [GSE136831](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE136831)\n",
    "    * GSE136831_AllCells.Samples.CellType.MetadataTable.txt\n",
    "    * GSE136831_RawCounts_Sparse.mtx \n",
    "2. Take only samples where \"Disease_Identity\" == \"Control\"\n",
    "3. Make a AnnData (i.e. lung.h5ad) using the raw counts as the expression and the meta data as the observation matrix. Make sure to include the following two columns in the observation matrix:\n",
    "    * CellType_Category - coarse-grained label \n",
    "    * Manuscript_Identity - fine-grained label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tissue = \"lung\"\n",
    "\n",
    "filename = f\"{tissue}.h5ad\"\n",
    "parent_folder = \"../input/ipf\"\n",
    "\n",
    "full_data = sc.read(os.path.join(parent_folder, filename), dtype='float64')\n",
    "\n",
    "# filtering \n",
    "sc.pp.filter_cells(full_data, min_genes=cell_cutoffs[tissue]) \n",
    "sc.pp.filter_genes(full_data, min_cells=gene_cutoffs[tissue])\n",
    "\n",
    "if save_raw:\n",
    "    # filter using genes in the preprocessed data\n",
    "    filename = f\"{tissue}_processed{condition}.h5ad\"\n",
    "    proccessed_data = sc.read(os.path.join(parent_folder, filename), dtype='float64', backed=\"r\")\n",
    "\n",
    "    print(full_data.var.index.is_unique)\n",
    "    cur_genes = list(full_data.var.index.values)\n",
    "\n",
    "    idx_genes = [cur_genes.index(i) for i in proccessed_data.var.index.values]\n",
    "    full_data = full_data[:, idx_genes]\n",
    "\n",
    "    assert (full_data.var.index.values == proccessed_data.var.index.values).all()\n",
    "    assert (full_data.obs.index.values == proccessed_data.obs.index.values).all()\n",
    "\n",
    "    try:\n",
    "        full_data.__dict__['_raw'].__dict__['_var'] = full_data.__dict__['_raw'].__dict__['_var'].rename(columns={'_index': 'features'})\n",
    "    except AttributeError:\n",
    "        pass \n",
    "\n",
    "\n",
    "    filename = f\"{tissue}_raw{condition}.h5ad\"\n",
    "    full_data.write_h5ad(os.path.join(parent_folder, filename))\n",
    "\n",
    "if save_processed:\n",
    "\n",
    "    # normalie \n",
    "    sc.pp.normalize_total(full_data, target_sum=1e4)\n",
    "    sc.pp.log1p(full_data)\n",
    "\n",
    "    # given the large number of genes for this data; filter to keep only highly dispersed genes \n",
    "    sc.pp.highly_variable_genes(full_data, min_mean=0, max_mean = 1000, min_disp=0.01)\n",
    "    full_data = full_data[:, full_data.var.highly_variable]\n",
    "\n",
    "    # adata.raw = adata\n",
    "    sc.pp.scale(full_data, max_value=10)\n",
    "\n",
    "    # save \n",
    "    try:\n",
    "        full_data.__dict__['_raw'].__dict__['_var'] = full_data.__dict__['_raw'].__dict__['_var'].rename(columns={'_index': 'features'})\n",
    "    except AttributeError:\n",
    "        pass \n",
    "\n",
    "    filename = f\"{tissue}_processed{condition}.h5ad\"\n",
    "    full_data.write_h5ad(os.path.join(parent_folder, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### add highly variables genes selected by Seurat_v3 for lung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tissue = \"lung\"\n",
    "\n",
    "filename = f\"{tissue}.h5ad\"\n",
    "parent_folder = \"../input/ipf\"\n",
    "\n",
    "full_data = sc.read(os.path.join(parent_folder, filename), dtype='float64')\n",
    "\n",
    "# filtering \n",
    "sc.pp.filter_cells(full_data, min_genes=cell_cutoffs[tissue]) \n",
    "sc.pp.filter_genes(full_data, min_cells=gene_cutoffs[tissue])\n",
    "\n",
    "# selecting genes using Seurat v3 method \n",
    "sc.pp.highly_variable_genes(full_data, n_top_genes=topk, flavor='seurat_v3')  \n",
    "genes_variable = full_data.var.index[full_data.var.highly_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f\"{tissue}_processed.h5ad\"\n",
    "temp = sc.read(os.path.join(parent_folder, filename), dtype='float64', backed = \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Seurat selected genes not in dispersion-selected: 100\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of Seurat selected genes not in dispersion-selected: {len(set(genes_variable) - set(temp.var.index))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "highly_variable_seurat = np.repeat(0, temp.shape[1])\n",
    "\n",
    "for i in range(temp.shape[1]):\n",
    "    g = temp.var.index.values[i]\n",
    "    if g in genes_variable:\n",
    "        highly_variable_seurat[i] = 1\n",
    "        \n",
    "temp.var[\"highly_variable_seurat\"] =  highly_variable_seurat.astype(bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = f\"{tissue}_processed.h5ad\"\n",
    "temp.write_h5ad(os.path.join(parent_folder, filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocess HuBMAP datasets\n",
    "<a id=4></a>\n",
    "\n",
    "For each tissue, we made the data by concatenating multiple datasets from HuBMAP. Please see [HuBMAP_datasets_ID.xlsx](https://github.com/doraadong/UNIFAN/blob/main/tutorails/HuBMAP_datasets_ID.xlsx) for the dataset IDs for the corresponding tissues. All datasets are preprocessed using standardized [HuBMAP scRNA-seq pipeline](https://github.com/hubmapconsortium/salmon-rnaseq)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "... storing 'tissue' as categorical\n",
      "... storing 'predicted.id' as categorical\n",
      "... storing 'celltype' as categorical\n",
      "... storing 'tissue' as categorical\n",
      "... storing 'predicted.id' as categorical\n",
      "... storing 'celltype' as categorical\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "for tissue in [\"spleen\", \"thymus\", \"lymph_node\"]:\n",
    "    \n",
    "    filename = f\"{tissue}.h5ad\"\n",
    "    parent_folder = \"../input/hubmap\"\n",
    "\n",
    "    full_data = sc.read(os.path.join(parent_folder, filename), dtype='float64')\n",
    "\n",
    "    # filtering \n",
    "    sc.pp.filter_cells(full_data, min_genes=cell_cutoffs[tissue]) \n",
    "    sc.pp.filter_genes(full_data, min_cells=gene_cutoffs[tissue])\n",
    "    \n",
    "    if save_raw:     \n",
    "        try:\n",
    "            full_data.__dict__['_raw'].__dict__['_var'] = full_data.__dict__['_raw'].__dict__['_var'].rename(columns={'_index': 'features'})\n",
    "        except AttributeError:\n",
    "            pass \n",
    "        \n",
    "        filename = f\"{tissue}_raw{condition}.h5ad\"\n",
    "        full_data.write_h5ad(os.path.join(parent_folder, filename))\n",
    "            \n",
    "    if save_processed:\n",
    "        # selecting genes using Seurat v3 method \n",
    "        sc.pp.highly_variable_genes(full_data, n_top_genes=topk, flavor='seurat_v3')\n",
    "\n",
    "        if select_genes:\n",
    "            full_data = full_data[:, full_data.var.highly_variable]\n",
    "\n",
    "        # normalie \n",
    "        sc.pp.normalize_total(full_data, target_sum=1e4)\n",
    "        sc.pp.log1p(full_data)\n",
    "\n",
    "        # adata.raw = adata\n",
    "        sc.pp.scale(full_data, max_value=10)\n",
    "\n",
    "        # convert ensemble to gene symbols \n",
    "        import mygene\n",
    "        mg = mygene.MyGeneInfo()\n",
    "\n",
    "        genes = [g.split('.')[0] for g in full_data.var.index.values]\n",
    "\n",
    "        out = mg.querymany(genes, scopes='ensembl.gene', fields='symbol', species='human', returnall=True)\n",
    "\n",
    "\n",
    "        # check when not selecting genes \n",
    "        for i in out['out']:\n",
    "            if i['query'] == 'ENSG00000229425':\n",
    "                print(i)\n",
    "\n",
    "        for i in out['out']:\n",
    "            if i['query'] == 'ENSG00000130723':\n",
    "                print(i)\n",
    "\n",
    "        en2symbol = {}\n",
    "        for i in out['out']:\n",
    "            if 'symbol' in i.keys():\n",
    "                if i['query'] not in en2symbol.keys():\n",
    "                    en2symbol[i['query']] = [i['symbol']]\n",
    "                else:\n",
    "                    en2symbol[i['query']].append(i['symbol'])\n",
    "            else:\n",
    "                en2symbol[i['query']] = [i['query']]\n",
    "\n",
    "        symbols = []\n",
    "        for g in genes:\n",
    "            symbols.append(en2symbol[g][0])  # take the first one \n",
    "\n",
    "        full_data.var.index = symbols\n",
    "\n",
    "\n",
    "        # save \n",
    "        try:\n",
    "            full_data.__dict__['_raw'].__dict__['_var'] = full_data.__dict__['_raw'].__dict__['_var'].rename(columns={'_index': 'features'})\n",
    "        except AttributeError:\n",
    "            pass \n",
    "\n",
    "        filename = f\"{tissue}_processed{condition}.h5ad\"\n",
    "        full_data.write_h5ad(os.path.join(parent_folder, filename))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anno] *",
   "language": "python",
   "name": "conda-env-anno-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
